#!/bin/bash

set -euo pipefail

# Buildkite Test Analytics Upload Plugin
# Uploads JUnit XML test results to Buildkite Test Analytics with optional redaction

echo "üìä Starting test analytics upload process..."

# Get plugin configuration from environment variables
# Buildkite sets plugin configuration as BUILDKITE_PLUGIN_<PLUGIN_NAME>_<CONFIG_KEY>
file_pattern="${BUILDKITE_PLUGIN_TEST_ANALYTICS_FILE_PATTERN:-}"
redact="${BUILDKITE_PLUGIN_TEST_ANALYTICS_REDACT:-false}"
analytics_token_env="${BUILDKITE_PLUGIN_TEST_ANALYTICS_ANALYTICS_TOKEN_ENV:-BUILDKITE_ANALYTICS_TOKEN}"
upload_timeout="${BUILDKITE_PLUGIN_TEST_ANALYTICS_UPLOAD_TIMEOUT:-30}"
max_file_size="${BUILDKITE_PLUGIN_TEST_ANALYTICS_MAX_FILE_SIZE:-10}"
upload_parallelism="${BUILDKITE_PLUGIN_TEST_ANALYTICS_UPLOAD_PARALLELISM:-5}"

# Validate required configuration
if [[ "$file_pattern" == "null" || -z "$file_pattern" ]]; then
    echo "‚ùå file_pattern is required"
    exit 1
fi

# Get analytics token from environment variable
analytics_token="${!analytics_token_env:-}"
if [[ -z "$analytics_token" ]]; then
    echo "‚ùå Analytics token not found in environment variable: $analytics_token_env"
    exit 1
fi

# Check required tools
if ! command -v curl &> /dev/null; then
    echo "‚ùå curl is not installed or not in PATH"
    exit 1
fi

if ! command -v python3 &> /dev/null; then
    echo "‚ùå python3 is not installed or not in PATH"
    exit 1
fi

echo "üîç Searching for test files matching pattern: $file_pattern"

# Create temporary directory for processed files
temp_dir=$(mktemp -d)
cleanup() {
    echo "üßπ Cleaning up temporary files..."
    rm -rf "$temp_dir"
}
trap cleanup EXIT

# Function to redact XML content using Python script
redact_xml() {
    local input_file="$1"
    local output_file="$2"
    
    if [[ "$redact" == "true" ]]; then
        echo "üîí Redacting all sensitive data in $(basename "$input_file")..."
        
        # Get the directory where this script is located
        local script_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
        local python_redactor="$script_dir/../redact_xml.py"
        
        # Execute Python redaction script with both redaction options enabled
        if python3 "$python_redactor" "$input_file" "$output_file" --redact-names --redact-output; then
            echo "‚úÖ Successfully redacted $(basename "$input_file")"
        else
            echo "‚ùå Failed to redact $(basename "$input_file"), copying original file"
            cp "$input_file" "$output_file"
            return 1
        fi
    else
        echo "üìã No redaction requested, copying $(basename "$input_file") as-is"
        cp "$input_file" "$output_file"
    fi
}

# Function to upload file to Buildkite Test Analytics
upload_file() {
    local file_path="$1"
    local file_name=$(basename "$file_path")
    
    echo "üì§ Uploading $file_name to Buildkite Test Analytics..."
    
    # Check file size (compatible with both Linux and macOS)
    local file_size_bytes
    if [[ "$OSTYPE" == "darwin"* ]]; then
        file_size_bytes=$(stat -f%z "$file_path")
    else
        file_size_bytes=$(stat -c%s "$file_path")
    fi
    local file_size_mb=$(( file_size_bytes / 1024 / 1024 ))
    if [[ $file_size_mb -gt $max_file_size ]]; then
        echo "‚ö†Ô∏è  Skipping $file_name: file size (${file_size_mb}MB) exceeds limit (${max_file_size}MB)"
        return 1
    fi
    
    # Upload with curl
    local upload_response
    if upload_response=$(curl -s -w "%{http_code}" --max-time "$upload_timeout" \
        -X POST \
        -H "Authorization: Token token=$analytics_token" \
        -F "format=junit" \
        -F "data=@$file_path" \
        -F "run_env[CI]=buildkite" \
        -F "run_env[key]=$BUILDKITE_BUILD_ID" \
        -F "run_env[number]=$BUILDKITE_BUILD_NUMBER" \
        -F "run_env[job_id]=$BUILDKITE_JOB_ID" \
        -F "run_env[branch]=$BUILDKITE_BRANCH" \
        -F "run_env[commit_sha]=$BUILDKITE_COMMIT" \
        -F "run_env[message]=$BUILDKITE_MESSAGE" \
        -F "run_env[url]=$BUILDKITE_BUILD_URL" \
        https://analytics-api.buildkite.com/v1/uploads 2>/dev/null); then
        
        local http_code="${upload_response: -3}"
        local response_body="${upload_response%???}"
        
        if [[ "$http_code" =~ ^2[0-9][0-9]$ ]]; then
            echo "‚úÖ Successfully uploaded $file_name (HTTP $http_code)"
            return 0
        else
            echo "‚ùå Failed to upload $file_name (HTTP $http_code)"
            if [[ -n "$response_body" ]]; then
                echo "   Response: $response_body"
            fi
            return 1
        fi
    else
        echo "‚ùå Failed to upload $file_name (curl error or timeout)"
        return 1
    fi
}

# Find and process XML files
file_count=0
success_count=0
failed_count=0

# Use find with the glob pattern (handle symlinks properly)
# Use both native and symlink-aware search, then union the results
echo "üîç Searching for files with pattern: $file_pattern"

# Extract base directory from pattern (everything before the first **)
base_dir=""
if [[ "$file_pattern" == *"**"* ]]; then
    base_dir="${file_pattern%%/**}"
    file_suffix="${file_pattern#**/}"
else
    file_suffix="$file_pattern"
fi

echo "üìÅ Base directory: ${base_dir:-'.'}, File pattern: $file_suffix"

# Collect files from both approaches
declare -A unique_files
file_count_found=0

# Approach 1: Standard find (without following symlinks)
echo "üîç Standard search..."
while IFS= read -r -d '' xml_file; do
    if [[ -f "$xml_file" ]]; then
        unique_files["$xml_file"]=1
        ((file_count_found++))
    fi
done < <(find ${base_dir:-.} -path "./$file_pattern" -type f -print0 2>/dev/null)

# Approach 2: Symlink-aware search (if base directory exists and might be symlinked)
if [[ -n "$base_dir" && -d "$base_dir" ]]; then
    echo "üîó Symlink-aware search in $base_dir..."
    while IFS= read -r -d '' xml_file; do
        if [[ -f "$xml_file" ]]; then
            unique_files["$xml_file"]=1
            ((file_count_found++))
        fi
    done < <(find -L "$base_dir" -name "*.xml" -type f -print0 2>/dev/null)
fi

# Convert unique files to array
xml_files=()
for file in "${!unique_files[@]}"; do
    xml_files+=("$file")
done

echo "üîç Found ${#xml_files[@]} unique XML files (${file_count_found} total matches)"

# Process files with parallel uploads
echo "üöÄ Starting to process files with $upload_parallelism parallel jobs..."

# Function to process a batch of files
process_batch() {
    local batch_id="$1"
    shift  # Remove batch_id from arguments, remaining args are the files
    local files=("$@")
    
    echo "üîÑ [Batch $batch_id] Processing ${#files[@]} files..."
    
    # Create subdirectory for this batch to avoid collisions
    local batch_dir="$temp_dir/batch_${batch_id}"
    mkdir -p "$batch_dir"
    
    local batch_success=0
    local batch_failed=0
    
    # Process each file in this batch sequentially
    for xml_file in "${files[@]}"; do
        if [[ -n "$xml_file" && -f "$xml_file" ]]; then
            local processed_file="$batch_dir/$(basename "$xml_file")"
            
            echo "üîÑ [Batch $batch_id] Processing: $(basename "$xml_file")"
            
            # Process XML file (redact if requested, otherwise copy as-is)
            if redact_xml "$xml_file" "$processed_file"; then
                # Upload the file
                if upload_file "$processed_file"; then
                    echo "‚úÖ [Batch $batch_id] Upload successful: $(basename "$xml_file")"
                    ((batch_success++))
                else
                    echo "‚ùå [Batch $batch_id] Upload failed: $(basename "$xml_file")"
                    ((batch_failed++))
                fi
            else
                echo "‚ùå [Batch $batch_id] XML processing failed: $(basename "$xml_file")"
                ((batch_failed++))
            fi
        fi
    done
    
    # Write batch results
    echo "$batch_success" > "$temp_dir/batch_${batch_id}_success"
    echo "$batch_failed" > "$temp_dir/batch_${batch_id}_failed"
    echo "‚úÖ [Batch $batch_id] Completed: $batch_success successful, $batch_failed failed"
}

# Divide files into chunks for parallel processing
total_files=${#xml_files[@]}
if [[ $total_files -eq 0 ]]; then
    echo "‚ö†Ô∏è No files to process"
    exit 0
fi

# Calculate chunk size
chunk_size=$(( (total_files + upload_parallelism - 1) / upload_parallelism ))
echo "üì¶ Dividing $total_files files into chunks of ~$chunk_size files each"

# Start parallel batches
batch_pids=()
batch_id=0

for ((start=0; start<total_files; start+=chunk_size)); do
    # Get chunk of files for this batch
    end=$((start + chunk_size))
    if [[ $end -gt $total_files ]]; then
        end=$total_files
    fi
    
    # Extract chunk of files
    batch_files=("${xml_files[@]:$start:$((end-start))}")
    
    echo "üöÄ Starting batch $batch_id with ${#batch_files[@]} files (files $((start+1))-$end)"
    
    # Start batch process in background
    process_batch "$batch_id" "${batch_files[@]}" &
    batch_pids+=($!)
    
    ((batch_id++))
done

# Wait for all batches to complete
echo "‚è≥ Waiting for $batch_id batches to complete..."
for pid in "${batch_pids[@]}"; do
    wait "$pid"
done

# Count results from all batches
success_count=0
failed_count=0
for ((i=0; i<batch_id; i++)); do
    if [[ -f "$temp_dir/batch_${i}_success" ]]; then
        batch_success=$(cat "$temp_dir/batch_${i}_success")
        success_count=$((success_count + batch_success))
    fi
    if [[ -f "$temp_dir/batch_${i}_failed" ]]; then
        batch_failed=$(cat "$temp_dir/batch_${i}_failed")
        failed_count=$((failed_count + batch_failed))
    fi
done

file_count=$total_files

# Summary
echo ""
echo "üìä Test Analytics Upload Summary:"
echo "   Files found: $file_count"
echo "   Successfully uploaded: $success_count"
echo "   Failed uploads: $failed_count"

if [[ $file_count -eq 0 ]]; then
    echo "‚ö†Ô∏è  No XML files found matching pattern: $file_pattern"
    exit 0
elif [[ $failed_count -gt 0 ]]; then
    echo "‚ö†Ô∏è  Some uploads failed, but continuing build"
    exit 0
else
    echo "üéâ All test results uploaded successfully!"
fi
